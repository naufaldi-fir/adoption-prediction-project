{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.metrics import cohen_kappa_score\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "from sklearn.datasets import make_classification\r\n",
    "from sklearn.model_selection import RandomizedSearchCV\r\n",
    "\r\n",
    "\r\n",
    "#Load the data \r\n",
    "train=pd.read_csv('train.csv')\r\n",
    "\r\n",
    "#All features, that do not require further preprocessing: \r\n",
    "#['Type', 'Age', 'Gender', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed', 'Sterilized', 'Health', 'Quantity', 'Fee']\r\n",
    "feature_cols=['Type', 'Age', 'Gender', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed', 'Sterilized', 'Health', 'Quantity', 'Fee']\r\n",
    "\r\n",
    "#Define y and X\r\n",
    "y=train.AdoptionSpeed\r\n",
    "X_unscaled=train[feature_cols]\r\n",
    "#Scale all features\r\n",
    "scaler=StandardScaler()\r\n",
    "X_scaled=scaler.fit_transform(X_unscaled)\r\n",
    "X=pd.DataFrame(X_scaled)\r\n",
    "\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Judith\\Anaconda2\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Number of trees in random forest\r\n",
    "n_estimators = [int(x) for x in np.linspace(start = 1000, stop = 1500, num = 500)]\r\n",
    "# Number of features to consider at every split\r\n",
    "# max_features = ['sqrt', 'log2']\r\n",
    "# Maximum number of levels in tree\r\n",
    "max_depth = [int(x) for x in np.linspace(10, 11, num = 2)]\r\n",
    "# max_depth.append(None)\r\n",
    "# Minimum number of samples required to split a node\r\n",
    "min_samples_split = [20,25,30,35,40,45,50,55,60,65,70]\r\n",
    "# Minimum number of samples required at each leaf node\r\n",
    "min_samples_leaf = [5,6]\r\n",
    "# Method of selecting samples for training each tree\r\n",
    "#bootstrap = [True]\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "random_grid = {'n_estimators': n_estimators,\r\n",
    "               'max_depth': max_depth,\r\n",
    "               'min_samples_split': min_samples_split,\r\n",
    "               'min_samples_leaf': min_samples_leaf\r\n",
    "               }\r\n",
    "\r\n",
    "# Use the random grid to search for best hyperparameters\r\n",
    "# First create the base model to tune\r\n",
    "clf = RandomForestClassifier()\r\n",
    "# Random search of parameters, using 3 fold cross validation, \r\n",
    "# search across 100 different combinations, and use all available cores\r\n",
    "clf_random = RandomizedSearchCV(estimator = clf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\r\n",
    "# Fit the random search model\r\n",
    "clf_random.fit(X_train, y_train)\r\n",
    "clf_random.best_params_\r\n",
    "print(clf_random.best_params_)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 15.1min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 26.8min finished\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'n_estimators': 1051, 'min_samples_split': 70, 'max_depth': 10, 'min_samples_leaf': 5}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def evaluate(model, X_test, y_test):\r\n",
    "    y_pred= model.predict( X_test)\r\n",
    "    score=cohen_kappa_score(y_pred, y_test, weights='quadratic')\r\n",
    "    print('Model Performance')\r\n",
    "    print('Score: ', score)\r\n",
    "    return score\r\n",
    "\r\n",
    "base_model = RandomForestClassifier(n_estimators = 100, random_state = 42)\r\n",
    "base_model.fit(X_train, y_train)\r\n",
    "base_score = evaluate(base_model, X_test, y_test)\r\n",
    "\r\n",
    "best_random = clf_random.best_estimator_\r\n",
    "random_score = evaluate(best_random, X_test, y_test)\r\n",
    "\r\n",
    "print('Improvement of ', base_score-random_score)\r\n",
    "\r\n",
    "#Use RandomForest\r\n",
    "#X, y = make_classification(n_samples=1000, n_features=4, n_informative=2, n_redundant=0, random_state=0, shuffle=False)\r\n",
    "#X, y = make_classification(random_state=0)\r\n",
    "#clf = RandomForestClassifier(n_estimators=100, max_depth=29, random_state=1)\r\n",
    "#clf.fit(X_train, y_train)\r\n",
    "#y_pred=clf.predict(X_test)\r\n",
    "\r\n",
    "\r\n",
    "#Print out the quadratic weighted kappa score\r\n",
    "#print(cohen_kappa_score(y_pred, y_test, weights='quadratic'))"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2a63215fbb79f5e6055094b66a64ec41290143e1b1eeee0d1cd51cecfe4e3566"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 2.7.15 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}